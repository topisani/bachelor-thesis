\newcommand{\Block}[1]{\ensuremath{\textsc{#1}}\xspace}
\newcommand{\Ident}{\Block{ident}}
\newcommand{\Cut}{\Block{cut}}
\newcommand{\Sequential}{\Block{seq}}
\newcommand{\Parallel}{\Block{par}}
\newcommand{\Recursive}{\Block{rec}}
\newcommand{\Resample}{\Block{resample}}
\newcommand{\Split}{\Block{split}}
\newcommand{\Merge}{\Block{merge}}
\newcommand{\Mem}{\Block{mem}}
\newcommand{\Delay}{\Block{delay}}
\newcommand{\Ins}{\ensuremath{\textbf{ins}}\xspace}
\newcommand{\Outs}{\ensuremath{\textbf{outs}}\xspace}
\newcommand{\Sig}{\ensuremath{\mathbb{S}}\xspace}
\newcommand{\SigP}[1]{\ensuremath{\llbracket #1 \rrbracket}\xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Block Diagrams}
\label{chap:blocks}

\todo{Introduce the concept of block diagrams for describing signal processors}\\

\section{Algebra of Blocks}

In the 2002 paper \emph{An Algebraic approach to Block Diagram Constructions}\autocite{orlarey2002} Orlarey et al introduce a series of five
basic block diagram operations, which are expanded in \autocite{orlarey2004} with two extra compositional
operations, split and merge. The rest of this chapter introduces this algebra of blocks in a language very
similar to \autocite{orlarey2004}, with minor differences in syntax and semantics noted along the way.

\begin{description}
  \item[A Signal] is a discrete function of time, such that the value of a signal $s \in \Sig$ at time
        $t$ is denoted $s(t)$. The full set of all signals is written as
        $\Sig = \mathbb N \rightarrow \mathbb R$. Signals are mostly used in signal tuples, denoted as $(s_1, \dots, s_n) \in \Sig^n$. To
        simplify the semantic specifications in the following section, tuples of signal tuples are always flattened,
        i.e. $\forall s \in \Sig: s = (s)$, and $\forall a \in \Sig^n, b \in \Sig^m : (a, b) = (a_1, \dots, a_n, b_1, \dots, b_m)$

        In use with AD/DA converters and other audio software, it is convention to let the full range of signals be
        $[-1; 1]$, and mostly this is represented as a 32-bit floating point value. Notice however, that
        signals may exceed this range, although inputs and outputs of the top-level signal processor should not.

  \item[A Signal Processor] is a function $S^n \rightarrow S^m$, and the object of the model. Signal processors are
        a transformation from a number of \emph{input} signals to a number of \emph{output}
        signals, which are evaluated for each time value $t$ in order. The result
        $p(s)(t)$ of signal processor $p$ may depend on $s(t')$ for
        all $t' < t$, in other words, signal processors may have \emph{memory}.

        The full set of signal processors is notated as $\mathbb P = \bigcup_{n,m} \Sig^n \rightarrow \Sig^m$

  \item[A Block] is the computational unit used to model signal processors. It is described in terms of the
        recursive language $\mathbb D$:
        \begin{align*}
          d, d_1, d_2 \in \mathbb{D} & ::= b \in \mathbb{B}      \\
                                     & |\; \Ident                \\
                                     & |\; \Cut                  \\
                                     & |\; \Sequential(d_1, d_2) \\
                                     & |\; \Parallel(d_1, d_2)   \\
                                     & |\; \Recursive(d_1, d_2)  \\
                                     & |\; \Split(d_1, d_2)      \\
                                     & |\; \Merge(d_1, d_2)      \\
        \end{align*}
        Here, $\mathbb B$ denotes a domain-specific set of primitive blocks. Some of these will be
        addressed in a later section.

        Faust and the related papers\autocite{orlarey2002,orlarey2004} uses single-character operator syntax for the basic
        operators of $\mathbb D$, but since the same syntax cannot be achieved exactly in C++, I will be
        referring to them by their names as prefix functions to avoid confusion. The later chapter on the C++
        implementation will cover the chosen syntax.

        To separate the syntax of blocks from the semantics, the function $\SigP{\ .\ } : \mathbb D
          \rightarrow \mathbb P$ is used to map a
        block diagram $d$ to the corresponding signal processor $\SigP{d}$.

        We also introduce the type-like syntax $d : i \rightarrow o$ to mean $\SigP{d} : \Sig^i \rightarrow \Sig^o$. This is useful
        for declaring the type rules, which are covered in the following section.
\end{description}

\subsection{Basic block operations}
Each of these seven block operations is described in detail by the FAUST authors in \autocite{orlarey2002}
and \autocite{orlarey2004}, so here I will only give a brief introduction to each one, along with an example
illustration and the type rules. Some are slightly simplified here when possible to still get the same
expressivity, in those cases it will be noted.

\subsubsection{Identity}
The $\Ident$ block is the simplest block - it simply takes one input signal, and outputs that
same signal untouched.

\begin{minipage}{0.5\linewidth}
  \begin{align*}
    \Ident: 1        & \rightarrow 1 \\
    \SigP{\Ident}(s) & = s
  \end{align*}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_ident}
    \includestandalone[]{Pictures/block_ident}
  \end{figure}
\end{minipage}

\subsubsection{Cut}
The $\Cut$ block takes one input signal and outputs nothing. It can be very useful for
discarding signals when composing blocks.

\begin{minipage}{0.5\linewidth}
  \begin{align*}
    \Cut: 1        & \rightarrow 0 \\
    \SigP{\Cut}(s) & = ()
  \end{align*}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_cut}
    \includestandalone[]{Pictures/block_cut}
  \end{figure}
\end{minipage}

\subsubsection{Sequential block composition}
\label{sec:block_seq}
The simplest composition of two blocks is passing the outputs of one block to the inputs of another in
sequence. It requires the number of outputs of the first block to equal the number of inputs on the second.
Faust has defined semantics for when this is not the case as well, but since those cases can all be covered
by combinations of sequential and parallel compositions, they have been left out here for simplicity.

\begin{minipage}{0.5\linewidth}
  \begin{prooftree}
    \AxiomC{$d_1 : n \rightarrow p$}
    \AxiomC{$d_2 : p \rightarrow m$}
    \BinaryInfC{$\Sequential(d_1, d_2) : n \rightarrow m$}
  \end{prooftree}
  \begin{align*}
    \SigP{\Sequential(d_1, d_2)}(s_1, \dots, s_n)    ={} & \SigP{d_2}\left(\SigP{d_1}(s_1, \dots, s_n)\right)
  \end{align*}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_seq}
    \includestandalone[]{Pictures/block_seq}
  \end{figure}
\end{minipage}

\subsubsection{Parallel block composition}
The parallel composition of two blocks can be intuitively seen as a concatenation of their input and output
signals, resulting in a block where the two components are evaluated separately on their own segments of the
input.

\begin{minipage}{0.5\linewidth}
  \begin{prooftree}
    \AxiomC{$d_1 : i_1 \rightarrow o_1$}
    \AxiomC{$d_2 : i_2 \rightarrow o_2$}
    \BinaryInfC{$\Parallel(d_1, d_2) : i_1 + i_2 \rightarrow o_1 + o_2$}
  \end{prooftree}
  \begin{align*}
    \SigP{\Parallel(d_1, d_2)}(s_1, \dots, s_{i_1}, x_1, \dots, x_{i_2}) ={} ( & \SigP{d_1}(s_1, \dots, s_{i_1}),   \\
                                                                               & \SigP{d_2}(x_{1}, \dots, x_{i_2})) \\
  \end{align*}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_par}
    \includestandalone[]{Pictures/block_par}
  \end{figure}
\end{minipage}

\subsubsection{Recursive block composition}
The recursive block composition is the most complex. Its purpose is to create cycles in the block diagram, by
allowing a block to access the output it generated in the previous iteration. The outputs of
$d_1$ are connected to the corresponding inputs of $d_2$, and the outputs
of $d_2$ are connected to the corresponding inputs of $d_1$. The inputs to
the composition are the remaining inputs to $d_1$, and the outputs are all outputs of
$d_1$.

Since the recursion requires a cycle, the output from $d_1$ that is passed to
$d_2$ is delayed by one sample, i.e. by one iteration. On the illustrations, this is denoted
by a small square on the connection.

\begin{minipage}{0.5\linewidth}
  \begin{prooftree}
    \AxiomC{$d_1 : i_1 \rightarrow o_1$}
    \AxiomC{$d_2 : i_2 \rightarrow o_2$}
    \AxiomC{$o_2 \leq i_1$}
    \AxiomC{$i_2 \leq o_1$}
    \QuaternaryInfC{$\Recursive(d_1, d_2) : i_1 - o_2 \rightarrow o_1$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\begin{array}{l}
          \SigP{d_1}(r_1, \dots, r_{o_2}, s_1, \dots, s_{n}) = (y_1,\dots, y_{o_1}) \\
          \SigP{d_2}(y'_1,\dots, y'_{i_2}) = (r_1, \dots, r_{o_2})
        \end{array}$}
    \UnaryInfC{$\SigP{\Recursive(d_1, d_2)}(s_1, \dots, s_{n}) ={} (y_1, \dots, y_{o_2})$}
  \end{prooftree}
  \vspace{\baselineskip}
  Where $y'$ is the signal $y$ delayed by one sample, i.e
  $$
    \forall y \in \Sig, t \in \mathbb{N}^+ : y'(0) = 0, y'(t) = y(t - 1)
  $$
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_rec}
    \includestandalone[]{Pictures/block_rec}
  \end{figure}
\end{minipage}

\subsubsection{Split block composition}
The split composition is used to sequentially compose blocks where the first one has fewer outputs than the
second has inputs. The output signals are connected by repeating the entire output tuple the apropriate
number of times, and this number is required to be an integer. This means $\Ins(d_2)$ must be an
exact multiple of $\Outs(d_1)$. \newcommand{\Mod}{\mathrm{\ mod\ }}
\begin{minipage}{0.5\linewidth}
  \begin{prooftree}
    \AxiomC{$d_1 : i_1 \rightarrow o_1$}
    \AxiomC{$d_2 : o_1 * k \rightarrow o_2$}
    \AxiomC{$k \in \mathbb{N}$}
    \TrinaryInfC{$\Split(d_1, d_2) : i_1 \rightarrow o_2$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\begin{array}{l}
          \SigP{d_1}(s_1, \dots, s_{i_1}) = (x_1, \dots, x_{o_1}) \\
          \forall j \in \{1, \dots, i_2\} y_j = x_{j \mod o_1}
        \end{array}$}
    \UnaryInfC{$\SigP{\Split(d_1, d_2)}(s_1, \dots, s_{i_1}) ={} \SigP{d_2}(y_1, \dots, y_{i_2})$}
  \end{prooftree}\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_split}
    \includestandalone[]{Pictures/block_split}
  \end{figure}
\end{minipage}

Note that $\Split(d_1, d_2)$ is equal to $\Sequential(d_1, d_2)$ when $k = 1$

\subsubsection{Merge block composition}

Merge composition is the inverse operation of split composition, i.e. it is used to sequentially compose two
blocks where the first one has more outputs than the second one. It places similar restrictions on
$d_1$ and $d_2$ as split composition, i.e. it requires
$\Outs(d_1) = \Ins(d_2) * k$, where $k$ is an integer.

When multiple outputs from $d_1$ are connected to a single input on $d_2$,
the signals are summed. Like split composition, $\Merge(d_1, d_2)$ is also equivalent
$\Sequential(d_1, d_2)$ when $k = 1$.

\begin{minipage}{0.5\linewidth}
  \begin{prooftree}
    \AxiomC{$d_1 : i_1 \rightarrow i_2 * k$}
    \AxiomC{$d_2 : i_2 \rightarrow o_2$}
    \AxiomC{$k \in \mathbb{N}$}
    \TrinaryInfC{$\Merge(d_1, d_2) : i_1 \rightarrow o_2$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\begin{array}{l}
          \SigP{d_1}(s_1, \dots, s_{i_1})      = (x_1, \dots, x_{o_1}) \\
          \forall j \in \{1, \dots, i_2\}, y_j = \sum^{k -1}_{l=0} x_{j + k * i_2}
        \end{array}$}
    \UnaryInfC{$\SigP{\Merge(d_1, d_2)}(s_1, \dots, s_{i_1}) ={} \SigP{d_2}(y_1, \dots, y_{i_2})$}
  \end{prooftree}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_merge}
    \includestandalone[]{Pictures/block_merge}
  \end{figure}
\end{minipage}

\subsection{Domain Specific Blocks}

As mentioned in the beginning of this chapter, the full set of blocks includes some domain-specific
primitives, denoted by the set $\mathbb B$. These are the blocks that perform actual useful
operations on the signals, and the blocks defined until now, are used to compose the primitives in
$\mathbb B$ into block diagrams.

This set can be extended with many more operations, but some of the most important ones are covered here.
Faust itself includes quite a few more\autocite{orlarey2004}, such as comparisons, branching, and UI
elements. During the following chapters more will be defined as well, and adding additional blocks should be
easy with the information given here.

\subsubsection{Arithmetic}
\label{sec:block_arithmetic}
The most basic blocks perform arithmetic operations on pairs of signals. For all operators
$@$ in ${+, -, *, /}$, a block with the following properties is defined:

\begin{minipage}{0.5\linewidth}
  \begin{align*}
    @                     & : 2 \rightarrow 1 \\
    \SigP{@}(s_1, s_2)(t) & = s_1(t) @ s_2(t) \\
  \end{align*}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_arithmetic}
    \includestandalone[]{Pictures/block_plus}
  \end{figure}
\end{minipage}

Keep in mind that these blocks are primitive, and while FAUST as well as EDA use infix operator syntax for
them, they are not compositional operators, meaning the block itself is not parameterized.

\subsubsection{Memory}

DSP operations commonly depend on previous signal values, and while the recursive composition often covers
those usecases, some are better suited with a simple memory block. It takes one input signal, and outputs
that same signal delayed by a single sample, and the very first sample has the value zero:

\begin{minipage}{0.5\linewidth}
  \begin{align*}
    \Mem               & : 1 \rightarrow 1           \\
    \SigP{@}(s)(0) = 0 & , \SigP{@}(s)(t + 1) = s(t) \\
  \end{align*}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{figure}[H]
    \centering
    \label{fig:block_mem}
    \includestandalone[]{Pictures/block_mem}
  \end{figure}
\end{minipage}

Memory blocks are often chained by sequential composition for longer delays, and this is denoted
$\Mem^n$. The corresponding signal processor becomes

\[
  \SigP{\Mem^n}(s)(t) =
  \begin{cases}
    s(t - n) & \text{if } t \geq n \\
    0        & \text{otherwise}
  \end{cases}
\]

\subsubsection{Delay}
\label{sec:block_delay}

By composing memory blocks, one can get a delay of arbitrary length, however, sometimes this length needs to
vary at runtime. For this, we have the \Delay block. Given two signals $(d, s)$, this block
outputs $s$ delayed by $d(t)$ samples.

\begin{align*}
  \Delay                 & : 2 \rightarrow 1            \\
  \SigP{\Delay}(d, s)(t) & = \begin{cases}
    s(t - d(t)) & \text{if } t \geq d \\
    0           & \text{otherwise}
  \end{cases}
\end{align*}

In implementations of this block, there may need to be some constraint on the value of
$d(t)$, and/or some buffer-growth policy that results in slightly different semantics.
